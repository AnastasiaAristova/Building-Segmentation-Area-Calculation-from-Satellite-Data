# Building-Segmentation-Area-Calculation-from-Satellite-Data

В данном проекте решается задача семантической сегментации зданий на спутниковых снимках с последующим расчетом площади застройки. 
Для обучения использовался датасет Inria Aerial Image Labeling. Описание датасета можно найти [здесь](https://project.inria.fr/aerialimagelabeling/).
Тестовый датасет был подготовлен с помощью [Google Earth Engine](https://earthengine.google.com/). Инструкция по работе с [Google Earth Engine](https://developers.google.com/earth-engine/guides/access). Разметка тестового датасета была выполнена вручную с помощью инструмента [CVAT](https://www.cvat.ai/).
В качестве архитектуры сети использовалась Unet - подобная архитектура. 
В качестве функции потерь использовалась Unified Focal Loss.
Для оценки модели использовались метрики: IoU, Dice, Precision, Recall.

Значения метрик обученной модели:

IoU = 0.718109

Dice = 0.821252

Precision = 0.789574

Recall = 0.904220

Для инференса модели реализовано веб-приложение на основе Streamlit.

Структура репозитория:

.

├── notebooks/                                      # Jupyter ноутбуки

│   ├── Подготовка тренировочного датасета.ipynb    

│   ├── Подготовка тестового датасета.ipynb        

│   ├── Pipeline Lite.ipynb                         # Обучение модели на сокращенном датасете

│   ├── Pipeline Full.ipynb                         # Обучение модели на полном датасете

│   ├── Инференс модели.ipynb                       

│   └── демо-приложение Streamlit.ipynb             # Запуск демо для Google Colab

├── streamlit_app/                                  # Streamlit приложение

│   ├── demo.py                                     # Основной скрипт

│   └── backbone.py                                 # Вспомогательные функции

└── README.md

Все ноутбуки оформлены в виде отчета: содержат код, комментарии и выводы по исследованиям. Просмотр и запуск ноутбуков необходимо выполнять в той же последовательности, как они описаны ниже.

В ноутбуке "Подготовка тренировочного датасета.ipynb" выполняется загрузка датасета с сайта и его подготовка для данного проекта. Готовый датасет сохраняется на Google Диск. Для использования замените указанные пути на свои. Готовый [датасет]( https://drive.google.com/file/d/1oxlMgr6C3jkb827iYrL2B6EPwa_ONoRu/view?usp=sharing).

В ноутбуке "Подготовка тестового датасета.ipynb" выполняется загрузка данных с Google Earth Engine и подготовка тестового датасета. Готовый датасет сохраняется на Google Диск. Для использования замените указанные пути на свои. Полученные изображения размечались с помощью CVAT и затем полный датасет был загружен на Google Диск. Готовый [датасет](https://drive.google.com/file/d/1aswekfugAaXXUEA5jPZoSqvyFPv_PLzF/view?usp=sharing).

В ноутбуке "Pipeline Lite.ipynb" реализован полный пайплайн обучения на неполном датасете. В нем реализованы подгрузка датасета, архитектура модели, метрики и функции потерь, функции обучения и тестирования. Также ноутбук содержит обоснование выбора функции потерь и несколько экспериментов с обучением.

В ноутбуке "Pipeline Full.ipynb" реализован полный пайплайн обучения на полном датасете с несколькими экспериментами и сравнениями разных вариантов обучения. 

В ноутбуках "Pipeline Lite.ipynb" и "Pipeline Full.ipynb" уже реализована подгрузка готовых датасетов. Для подгрузки со своего Google диска следуйте [инструкции](https://www.kaggle.com/code/vignesh369/how-to-access-google-drive-contents-in-kaggle/notebook).

В ноутбуке "Инференс модели.ipynb" выполнен инференс модели - сегментация изображения и подсчет площади застройки. Для работы необходимо загрузить [веса модели best_iou.pt и примеры изображений](https://drive.google.com/drive/folders/1f1wUDpApMwzsIsj8DLQfq7H_t5WRGRsD?usp=sharing) к себе на Google-диск или в сессионное хранилище ноутбука и поменять пути. 

В ноутбуке "демо-приложение Streamlit.ipynb" реализован запуск демо-приложения с помощью Google Colab. Для запуска необходимо сохранить файлы demo.py и backbone.py из папки streamlit_app/ в сессионное хранилище.
Также приложение можно запустить с локального компьютера. Для этого необходимо сохранить папку streamlit_app/ со всеми файлами, установить необходимые зависимости и запустить команду: streamlit run streamlit_app/demo.py. 

*Примечание*: при запуске приложение на CPU примерное время выполнения расчетов - 15 минут. Рекомендуется использовать GPU.

